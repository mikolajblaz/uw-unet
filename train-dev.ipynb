{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from unet import UnetTrainer\n",
    "import data\n",
    "import config\n",
    "\n",
    "trainer = UnetTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going down\n",
      "shape (?, 512, 512, 1)\n",
      "shape (?, 512, 512, 64)\n",
      "shape (?, 256, 256, 64)\n",
      "Going up\n",
      "shape (?, 256, 256, 128)\n",
      "Upscaled layer shape: (?, 512, 512, 64)\n",
      "Previous layer shape: (?, 512, 512, 64)\n",
      "shape (?, 512, 512, 128)\n",
      "shape (?, 512, 512, 64)\n",
      "shape (?, 512, 512, 66)\n",
      "list of variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'conv2d_transpose/kernel:0', 'conv2d_transpose/bias:0', 'conv2d_4/kernel:0', 'conv2d_4/bias:0', 'conv2d_5/kernel:0', 'conv2d_5/bias:0', 'conv2d_6/kernel:0', 'conv2d_6/bias:0', 'beta1_power:0', 'beta2_power:0', 'conv2d/kernel/Adam:0', 'conv2d/kernel/Adam_1:0', 'conv2d/bias/Adam:0', 'conv2d/bias/Adam_1:0', 'conv2d_1/kernel/Adam:0', 'conv2d_1/kernel/Adam_1:0', 'conv2d_1/bias/Adam:0', 'conv2d_1/bias/Adam_1:0', 'conv2d_2/kernel/Adam:0', 'conv2d_2/kernel/Adam_1:0', 'conv2d_2/bias/Adam:0', 'conv2d_2/bias/Adam_1:0', 'conv2d_3/kernel/Adam:0', 'conv2d_3/kernel/Adam_1:0', 'conv2d_3/bias/Adam:0', 'conv2d_3/bias/Adam_1:0', 'conv2d_transpose/kernel/Adam:0', 'conv2d_transpose/kernel/Adam_1:0', 'conv2d_transpose/bias/Adam:0', 'conv2d_transpose/bias/Adam_1:0', 'conv2d_4/kernel/Adam:0', 'conv2d_4/kernel/Adam_1:0', 'conv2d_4/bias/Adam:0', 'conv2d_4/bias/Adam_1:0', 'conv2d_5/kernel/Adam:0', 'conv2d_5/kernel/Adam_1:0', 'conv2d_5/bias/Adam:0', 'conv2d_5/bias/Adam_1:0', 'conv2d_6/kernel/Adam:0', 'conv2d_6/kernel/Adam_1:0', 'conv2d_6/bias/Adam:0', 'conv2d_6/bias/Adam_1:0']\n",
      "dataset_subset/training/images/ dataset_subset/training/labels_plain/\n",
      "Epoch 0 starts\n",
      "[[b'/home/mikib/uw/dl/zad2/dataset_subset/training/images/0035fkbjWljhaftpVM37-g.jpg'\n",
      "  b'/home/mikib/uw/dl/zad2/dataset_subset/training/labels_plain/0035fkbjWljhaftpVM37-g.png']\n",
      " [b'/home/mikib/uw/dl/zad2/dataset_subset/training/images/00rKt4pJadETqgb3NYonSA.jpg'\n",
      "  b'/home/mikib/uw/dl/zad2/dataset_subset/training/labels_plain/00rKt4pJadETqgb3NYonSA.png']\n",
      " [b'/home/mikib/uw/dl/zad2/dataset_subset/training/images/014cEvKoAuTJgL6yJvmZow.jpg'\n",
      "  b'/home/mikib/uw/dl/zad2/dataset_subset/training/labels_plain/014cEvKoAuTJgL6yJvmZow.png']]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'batch_xs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-d36e53994329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/uw/dl/zad2/unet.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs_n, dir_base, save_path)\u001b[0m\n\u001b[1;32m    180\u001b[0m                         \u001b[0;31m# batch_xs, batch_ys = self.sess.run(train_batch_getter)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                         \u001b[0;31m# TODO: connect ^ v ^ v ^\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                         \u001b[0mvloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m                         \u001b[0mlogs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_writer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_xs' is not defined"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "trainer.train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import NET_INPUT_SIZE\n",
    "self = trainer\n",
    "\n",
    "def create_model():\n",
    "    tf.reset_default_graph()\n",
    "    self.x = tf.placeholder(tf.float32, [None, NET_INPUT_SIZE[0], NET_INPUT_SIZE[1], 1], name='x')\n",
    "    self.y_target = tf.placeholder(tf.float32, [None, NET_INPUT_SIZE[0], NET_INPUT_SIZE[1], 65], name='y_target')\n",
    "\n",
    "    signal = self.x\n",
    "    print_shape = lambda: print('shape', signal.get_shape())\n",
    "\n",
    "    num_filters = 65\n",
    "    kernel_size = 3\n",
    "\n",
    "    # Conv layers\n",
    "    print('Downscaling part')\n",
    "    signal = tf.layers.conv2d(\n",
    "        inputs=signal,\n",
    "        filters=num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "        name='conv',\n",
    "        padding='SAME'\n",
    "    )\n",
    "    print_shape()\n",
    "    signal = tf.layers.max_pooling2d(signal, pool_size=2, strides=2, name='pool')\n",
    "\n",
    "    print_shape()\n",
    "    signal = tf.layers.conv2d_transpose(\n",
    "        inputs=signal,\n",
    "        filters=num_filters,\n",
    "        strides=2,\n",
    "        kernel_size=kernel_size,\n",
    "        name='conv_transpose',\n",
    "        padding='SAME'\n",
    "    )\n",
    "    print_shape()\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-5656ec7e1a2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'create_model' is not defined"
     ]
    }
   ],
   "source": [
    "signal = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (?, 572, 572, 65)\n"
     ]
    }
   ],
   "source": [
    "print_shape = lambda x: print('shape', x.get_shape())\n",
    "print_shape(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = tf.nn.softmax_cross_entropy_with_logits_v2(logits=signal, labels=self.y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 572, 572)\n"
     ]
    }
   ],
   "source": [
    "print(softmax.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.constant([1., 2., 3.])\n",
    "labels = tf.constant([0., 1., 0.])\n",
    "soft = tf.nn.softmax(logits)\n",
    "sigm = tf.sigmoid(logits)\n",
    "sigm_cross = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "soft_cross = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels)\n",
    "\n",
    "cross = labels * tf.log(soft)\n",
    "mean = - tf.reduce_sum(cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.09003057, 0.24472848, 0.66524094], dtype=float32),\n",
       " array([0.7310586 , 0.880797  , 0.95257413], dtype=float32),\n",
       " array([1.3132617, 0.126928 , 3.0485873], dtype=float32),\n",
       " 1.4076059,\n",
       " array([-0.       , -1.4076059, -0.       ], dtype=float32),\n",
       " 1.4076059]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    res = sess.run([soft, sigm, sigm_cross, soft_cross, cross, mean])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.asarray([1., 2., 3.])\n",
    "import numpy as np\n",
    "a2 = np.stack([a * i for i in range(1, 5)])\n",
    "a3 = np.stack([a2, a2 * 10])\n",
    "a3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  1.,   2.,   3.],\n",
       "        [  2.,   4.,   6.],\n",
       "        [  3.,   6.,   9.],\n",
       "        [  4.,   8.,  12.]],\n",
       "\n",
       "       [[ 10.,  20.,  30.],\n",
       "        [ 20.,  40.,  60.],\n",
       "        [ 30.,  60.,  90.],\n",
       "        [ 40.,  80., 120.]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.asarray([0., 1., 0.])\n",
    "bb = np.stack([b] * 4)\n",
    "b3 = np.stack([bb, bb])\n",
    "b3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.constant(a3)\n",
    "labels = tf.constant(b3)\n",
    "soft = tf.nn.softmax(logits)\n",
    "sigm_cross = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "soft_cross = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels)\n",
    "\n",
    "cross = labels * tf.log(soft)\n",
    "mean = - tf.reduce_sum(cross, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[9.00305732e-02, 2.44728471e-01, 6.65240956e-01],\n",
       "         [1.58762400e-02, 1.17310428e-01, 8.66813332e-01],\n",
       "         [2.35563308e-03, 4.73141552e-02, 9.50330212e-01],\n",
       "         [3.29320439e-04, 1.79802867e-02, 9.81690393e-01]],\n",
       " \n",
       "        [[2.06106005e-09, 4.53978686e-05, 9.99954600e-01],\n",
       "         [4.24835425e-18, 2.06115362e-09, 9.99999998e-01],\n",
       "         [8.75651076e-27, 9.35762297e-14, 1.00000000e+00],\n",
       "         [1.80485139e-35, 4.24835426e-18, 1.00000000e+00]]]),\n",
       " array([[[1.31326169e+00, 1.26928011e-01, 3.04858735e+00],\n",
       "         [2.12692801e+00, 1.81499279e-02, 6.00247569e+00],\n",
       "         [3.04858735e+00, 2.47568514e-03, 9.00012340e+00],\n",
       "         [4.01814993e+00, 3.35406373e-04, 1.20000061e+01]],\n",
       " \n",
       "        [[1.00000454e+01, 2.06115362e-09, 3.00000000e+01],\n",
       "         [2.00000000e+01, 4.24835426e-18, 6.00000000e+01],\n",
       "         [3.00000000e+01, 8.75651076e-27, 9.00000000e+01],\n",
       "         [4.00000000e+01, 1.80485139e-35, 1.20000000e+02]]]),\n",
       " array([[ 1.40760596,  2.14293163,  3.05094576,  4.0184793 ],\n",
       "        [10.0000454 , 20.        , 30.        , 40.        ]]),\n",
       " array([[[ -0.        ,  -1.40760596,  -0.        ],\n",
       "         [ -0.        ,  -2.14293163,  -0.        ],\n",
       "         [ -0.        ,  -3.05094576,  -0.        ],\n",
       "         [ -0.        ,  -4.0184793 ,  -0.        ]],\n",
       " \n",
       "        [[ -0.        , -10.0000454 ,  -0.        ],\n",
       "         [ -0.        , -20.        ,  -0.        ],\n",
       "         [ -0.        , -30.        ,  -0.        ],\n",
       "         [ -0.        , -40.        ,   0.        ]]]),\n",
       " array([[ 1.40760596,  2.14293163,  3.05094576,  4.0184793 ],\n",
       "        [10.0000454 , 20.        , 30.        , 40.        ]])]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    res = sess.run([soft, sigm_cross, soft_cross, cross, mean])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_cross_ = res[2]\n",
    "soft_cross_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (2, 4, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(4)])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_shape(logits)\n",
    "tf.argmax(logits, axis=-1).get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_subset/training/images/ dataset_subset/training/labels_plain/\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "from data import full_pipeline\n",
    "\n",
    "dataset_train, dataset_valid, batches_per_epoch_train, batches_per_epoch_valid = full_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_getter = dataset_train.make_one_shot_iterator().get_next()\n",
    "valid_batch_getter = dataset_valid.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[3 4 5]\n",
      "[6 7 8]\n",
      "[9 0 1]\n",
      "\n",
      "[10 11 12]\n",
      "[13 14 15]\n",
      "[16 17 18]\n",
      "[19 20 21]\n",
      "[22 23 24]\n",
      "[25 26 27]\n",
      "[28 29 10]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    for _ in range(batches_per_epoch_train):\n",
    "        print(sess.run(train_batch_getter))\n",
    "    print()\n",
    "    for _ in range(batches_per_epoch_valid):\n",
    "        print(sess.run(valid_batch_getter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.placeholder(tf.bool)\n",
    "c = tf.cond(b, lambda: train_batch_getter, lambda: valid_batch_getter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16 17 18]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(c, feed_dict={b: False}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
