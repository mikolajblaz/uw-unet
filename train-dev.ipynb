{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from unet import UnetTrainer\n",
    "import data\n",
    "import config\n",
    "\n",
    "trainer = UnetTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going down\n",
      "shape (?, 572, 572, 1)\n",
      "shape (?, 572, 572, 64)\n",
      "shape (?, 286, 286, 64)\n",
      "Going up\n",
      "shape (?, 286, 286, 128)\n",
      "Upscaled layer shape: (?, 572, 572, 64)\n",
      "Previous layer shape: (?, 572, 572, 64)\n",
      "shape (?, 572, 572, 128)\n",
      "shape (?, 572, 572, 64)\n",
      "shape (?, 572, 572, 66)\n",
      "list of variables ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'conv2d_transpose/kernel:0', 'conv2d_transpose/bias:0', 'conv2d_4/kernel:0', 'conv2d_4/bias:0', 'conv2d_5/kernel:0', 'conv2d_5/bias:0', 'conv2d_6/kernel:0', 'conv2d_6/bias:0', 'beta1_power:0', 'beta2_power:0', 'conv2d/kernel/Adam:0', 'conv2d/kernel/Adam_1:0', 'conv2d/bias/Adam:0', 'conv2d/bias/Adam_1:0', 'conv2d_1/kernel/Adam:0', 'conv2d_1/kernel/Adam_1:0', 'conv2d_1/bias/Adam:0', 'conv2d_1/bias/Adam_1:0', 'conv2d_2/kernel/Adam:0', 'conv2d_2/kernel/Adam_1:0', 'conv2d_2/bias/Adam:0', 'conv2d_2/bias/Adam_1:0', 'conv2d_3/kernel/Adam:0', 'conv2d_3/kernel/Adam_1:0', 'conv2d_3/bias/Adam:0', 'conv2d_3/bias/Adam_1:0', 'conv2d_transpose/kernel/Adam:0', 'conv2d_transpose/kernel/Adam_1:0', 'conv2d_transpose/bias/Adam:0', 'conv2d_transpose/bias/Adam_1:0', 'conv2d_4/kernel/Adam:0', 'conv2d_4/kernel/Adam_1:0', 'conv2d_4/bias/Adam:0', 'conv2d_4/bias/Adam_1:0', 'conv2d_5/kernel/Adam:0', 'conv2d_5/kernel/Adam_1:0', 'conv2d_5/bias/Adam:0', 'conv2d_5/bias/Adam_1:0', 'conv2d_6/kernel/Adam:0', 'conv2d_6/kernel/Adam_1:0', 'conv2d_6/bias/Adam:0', 'conv2d_6/bias/Adam_1:0']\n",
      "dataset_subset/training/images/ dataset_subset/training/labels_plain/\n",
      "Batches: (3, 572, 572, 1) (3, 572, 572)\n",
      "[10.465775, 0.028523196]\n",
      "Batches: (3, 572, 572, 1) (3, 572, 572)\n",
      "[925.5477, 0.09951587]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "trainer.train(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import NET_INPUT_SIZE\n",
    "self = trainer\n",
    "\n",
    "def create_model():\n",
    "    tf.reset_default_graph()\n",
    "    self.x = tf.placeholder(tf.float32, [None, NET_INPUT_SIZE[0], NET_INPUT_SIZE[1], 1], name='x')\n",
    "    self.y_target = tf.placeholder(tf.float32, [None, NET_INPUT_SIZE[0], NET_INPUT_SIZE[1], 65], name='y_target')\n",
    "\n",
    "    signal = self.x\n",
    "    print_shape = lambda: print('shape', signal.get_shape())\n",
    "\n",
    "    num_filters = 65\n",
    "    kernel_size = 3\n",
    "\n",
    "    # Conv layers\n",
    "    print('Downscaling part')\n",
    "    signal = tf.layers.conv2d(\n",
    "        inputs=signal,\n",
    "        filters=num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "        name='conv',\n",
    "        padding='SAME'\n",
    "    )\n",
    "    print_shape()\n",
    "    signal = tf.layers.max_pooling2d(signal, pool_size=2, strides=2, name='pool')\n",
    "\n",
    "    print_shape()\n",
    "    signal = tf.layers.conv2d_transpose(\n",
    "        inputs=signal,\n",
    "        filters=num_filters,\n",
    "        strides=2,\n",
    "        kernel_size=kernel_size,\n",
    "        name='conv_transpose',\n",
    "        padding='SAME'\n",
    "    )\n",
    "    print_shape()\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downscaling part\n",
      "shape (?, 572, 572, 65)\n",
      "shape (?, 286, 286, 65)\n",
      "shape (?, 572, 572, 65)\n"
     ]
    }
   ],
   "source": [
    "signal = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (?, 572, 572, 65)\n"
     ]
    }
   ],
   "source": [
    "print_shape = lambda x: print('shape', x.get_shape())\n",
    "print_shape(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = tf.nn.softmax_cross_entropy_with_logits_v2(logits=signal, labels=self.y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 572, 572)\n"
     ]
    }
   ],
   "source": [
    "print(softmax.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.constant([1., 2., 3.])\n",
    "labels = tf.constant([0., 1., 0.])\n",
    "soft = tf.nn.softmax(logits)\n",
    "sigm = tf.sigmoid(logits)\n",
    "sigm_cross = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "soft_cross = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels)\n",
    "\n",
    "cross = labels * tf.log(soft)\n",
    "mean = - tf.reduce_sum(cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.09003057, 0.24472848, 0.66524094], dtype=float32),\n",
       " array([0.7310586 , 0.880797  , 0.95257413], dtype=float32),\n",
       " array([1.3132617, 0.126928 , 3.0485873], dtype=float32),\n",
       " 1.4076059,\n",
       " array([-0.       , -1.4076059, -0.       ], dtype=float32),\n",
       " 1.4076059]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    res = sess.run([soft, sigm, sigm_cross, soft_cross, cross, mean])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.asarray([1., 2., 3.])\n",
    "import numpy as np\n",
    "a2 = np.stack([a * i for i in range(1, 5)])\n",
    "a3 = np.stack([a2, a2 * 10])\n",
    "a3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  1.,   2.,   3.],\n",
       "        [  2.,   4.,   6.],\n",
       "        [  3.,   6.,   9.],\n",
       "        [  4.,   8.,  12.]],\n",
       "\n",
       "       [[ 10.,  20.,  30.],\n",
       "        [ 20.,  40.,  60.],\n",
       "        [ 30.,  60.,  90.],\n",
       "        [ 40.,  80., 120.]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 3)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.asarray([0., 1., 0.])\n",
    "bb = np.stack([b] * 4)\n",
    "b3 = np.stack([bb, bb])\n",
    "b3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.constant(a3)\n",
    "labels = tf.constant(b3)\n",
    "soft = tf.nn.softmax(logits)\n",
    "sigm_cross = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels)\n",
    "soft_cross = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels)\n",
    "\n",
    "cross = labels * tf.log(soft)\n",
    "mean = - tf.reduce_sum(cross, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[9.00305732e-02, 2.44728471e-01, 6.65240956e-01],\n",
       "         [1.58762400e-02, 1.17310428e-01, 8.66813332e-01],\n",
       "         [2.35563308e-03, 4.73141552e-02, 9.50330212e-01],\n",
       "         [3.29320439e-04, 1.79802867e-02, 9.81690393e-01]],\n",
       " \n",
       "        [[2.06106005e-09, 4.53978686e-05, 9.99954600e-01],\n",
       "         [4.24835425e-18, 2.06115362e-09, 9.99999998e-01],\n",
       "         [8.75651076e-27, 9.35762297e-14, 1.00000000e+00],\n",
       "         [1.80485139e-35, 4.24835426e-18, 1.00000000e+00]]]),\n",
       " array([[[1.31326169e+00, 1.26928011e-01, 3.04858735e+00],\n",
       "         [2.12692801e+00, 1.81499279e-02, 6.00247569e+00],\n",
       "         [3.04858735e+00, 2.47568514e-03, 9.00012340e+00],\n",
       "         [4.01814993e+00, 3.35406373e-04, 1.20000061e+01]],\n",
       " \n",
       "        [[1.00000454e+01, 2.06115362e-09, 3.00000000e+01],\n",
       "         [2.00000000e+01, 4.24835426e-18, 6.00000000e+01],\n",
       "         [3.00000000e+01, 8.75651076e-27, 9.00000000e+01],\n",
       "         [4.00000000e+01, 1.80485139e-35, 1.20000000e+02]]]),\n",
       " array([[ 1.40760596,  2.14293163,  3.05094576,  4.0184793 ],\n",
       "        [10.0000454 , 20.        , 30.        , 40.        ]]),\n",
       " array([[[ -0.        ,  -1.40760596,  -0.        ],\n",
       "         [ -0.        ,  -2.14293163,  -0.        ],\n",
       "         [ -0.        ,  -3.05094576,  -0.        ],\n",
       "         [ -0.        ,  -4.0184793 ,  -0.        ]],\n",
       " \n",
       "        [[ -0.        , -10.0000454 ,  -0.        ],\n",
       "         [ -0.        , -20.        ,  -0.        ],\n",
       "         [ -0.        , -30.        ,  -0.        ],\n",
       "         [ -0.        , -40.        ,   0.        ]]]),\n",
       " array([[ 1.40760596,  2.14293163,  3.05094576,  4.0184793 ],\n",
       "        [10.0000454 , 20.        , 30.        , 40.        ]])]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    res = sess.run([soft, sigm_cross, soft_cross, cross, mean])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_cross_ = res[2]\n",
    "soft_cross_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (2, 4, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(4)])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_shape(logits)\n",
    "tf.argmax(logits, axis=-1).get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_subset/training/images/ dataset_subset/training/labels_plain/\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "from data import full_pipeline\n",
    "\n",
    "dataset_train, dataset_valid = full_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset_valid.make_one_shot_iterator()\n",
    "batch_getter = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 11 12]\n",
      "[13 14 15]\n",
      "[16 17 18]\n",
      "[19]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    while True:\n",
    "        try:\n",
    "            print(sess.run(batch_getter))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
